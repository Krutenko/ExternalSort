# External Sort
## _Принцип работы_
Задачей данного проекта является сортировка миллиарда чисел типа `double`. Числа должны быть записаны в файле, по одному на каждую строчку. На каждой строке должны быть одно число типа `double` и больше ничего. Если на строке находится хотя бы один лишний символ, она будет проигнорированна. Всего, не считая проигнорированные, в файле должно быть ровно миллиард чисел. Если их будет меньше, программа аварийно завершится. Если же больше, то будет рассмотрен только первый миллиард, остальное будет проигнорированно.
Программа принимает на вход три аргумента. Первый - режим работы: "-s" (основной, 1 000 000 000 чисел) или "-t" (тестовый, 1 000 чисел). Второй - файл, с исходным массивом чисел. Второй - название файла, в который будет записан отсортированный массив. Второй файл можно не указывать, тогда программа запишет массив в файл с названием "sorted.txt".

## _Алгоритм сортировки_
Миллиард чисел `double` занимает 7 ГБ памяти. Чтобы не хранить такой объём данных в памяти программы был использован алгоритм внешней сортировки. Исходный файл считывается блоками по 2 миллиона чисел. Блок хранится в виде `std::priority_queue`, где и производится сортировка. После чего очередной блок записывается в файл "parts/partN.txt", где N - номер блока, начиная с 1. После того, как было сгенерированно 500 промежуточных файлов, необходимо их объеденить в один итоговый. Для этого все файлы открываются одновременно, и из каждого промежуточного считывается первое значение. Затем выбирается наименьшее среди первых значений и записывается в итоговый файл. Считывается новое значение из того же файла, из которого было только что записанное. И так далее пока все файлы не закончатся. Такой метод сортировки занимает в среднем 3 часа, однако не требует хранения большого объёма данных в памяти и за счёт этого может быть применён и к большим массивам.

## _Распределённые вычисления_
Алгоритм можно разделить на два этапа:
- Формирование промежуточных файлов. Сортировка происходит внутри блоков, которые находятся в памяти программы по отдельности, поэтому невозможно сортировать разные блоки параллельно. Единственное, что можно оптимизировать с помощью многопоточности это чтение. Как известно чтение и запись занимают достаточно много времени, по сравнению с другими операциями, поэтому считывание блока производится в одном потоке, а его обработка и вывод в другом.
- Объединение промежуточных файлов в итоговый. Этот этап оптимизировать нельзя, поскольку из кучи поочерёдно выбирается одно наименьшее значение, которое затем сразу же заменяется другим. Невозможно предсказать, есть ли в текущей куче значение, которое следует записать следующим после наименьшего или нет. 

## _Сложность алгоритма_
Исходный массив записан в файл, поэтому прежде чем, приступить к сортировке, необходимо перенести его в память. Таким образом, сначала необходимо пройти по массиву один раз для записи в память, а потом второй раз для сортировки. Для оптимизации этого процесса была использована `std::priority_queue`, благодаря которой уже при считывании новое значение встаёт на своё упорядоченное место. Вставка в таком случае имеет сложность $$O(log(x))$$, где $$x$$ - число элементов в куче. Таким образом запись всех $$n$$ (где $$n$$ - это число элементов в каждом блоке) элементов в кучу и соответственно их сортировка имеет сложность $$\sum_{x=0}^{n} log(x)$$. Для того, чтобы иметь представление о значении данного выражения рассмотрим $$\int_{0}^{n} log(x)dx=n(log(n)-1)$$ Учитывая, что в нашем случае $$n=2'000'000$$, можно считать, что сложность алгоритма сортировки для одного блока $$O(n\cdot log(n))$$. Обозначим общее количество блоков как $$m$$, а общее число элементов во всём массиве как $$N$$. Такой алгоритм нужно провести для каждого блока, то есть общая сложность первого этапа равна $$O(m\cdot n \cdot log(n))=O(N\cdot log(n))$$.
На втором этапе также используется `std::priority_queue`, только теперь размером $$m$$. В эту очередь поочерёдно должен попасть каждый элемент массива. Однако её размер не превышает, а значит сложность вставки всегда $$O(log(m))$$. Общая же сложность этапа $$O(N\cdot log(m))$$.
Таким образом сложность всего алгоритма равняется $$O(N\cdot log(n)+N\cdot log(m))=O(N\cdot (log(n)+log(m)))=$$
$$=O(N\cdot log(nm))=O(N\cdot log(N))$$.

## _Точность_
Поскольку в исходном массиве числа с плавающей запятой, возникает проблема точности, ведь на вход могут подаваться числа любой точности, и если при повторной записи этих чисел в итоговый файл будет указаны точность больше или меньше исходной, числа могут не совпасть. Поэтому в данной программе точность каждого числа вычисляется и хранится вместе с ним в памяти, что гарантирует совпадение исходных и итоговых чисел. Однако если на вход будет подано число настолько большой точности, что оно не может быть точно конвертированно функцией `std::stod`, такое число будет пропущено. Также во входном файле не должно быть чисел с незначимыми нулями после запятой, так как они будут отброшены.

## _Тесты_
Так как файл с миллиардом чисел `double` занимает 12 ГБ, а сортировка такого файла занимает 3 часа, тесты проводились в основном на маленьком файле с 1 000 чисел. Для этого в программе есть специальный режим "-t", который требует на вход только 1 000 чисел, разбивая их на 50 блоков по 20. К программе прилагаются тестовые файлы.
- test1.txt содержит числа со случайной точностью от 4 до 10 для демонстрации сохранения этой точности в итоговом файле.
- test2.txt пустой и должен выдавать ошибку.
- test3.txt содержит 1001 число, 1 из которых слишком большое, чтобы поместиться в double. Из-за этого, оно будет проигнорированно, а тест пройден, так как без этого числа будет ровно 1000.
- test4.txt содержит строки с надписью "test" помимо 1000 строк с числами. Все строки с буквами будут проигнорированны и тест успешно выполнен.
- test5.txt состоит из 1000 нулей. На выходе получается точно такой же файл.

## _Платформа и сборка_
Программа поддерживает как Windows, так и Linux. На Windows собирается через Visual studio. Проект прилагается. Также в папке проекта находится Makefile для сборки под Linux.
